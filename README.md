# Perceptron

# Multilayer Perceptrons

## Training the network

    - backpropagation
    - gradient desecent

1. Forward Pass: Compute the outputs of the network for a given input.
2. Compute the Error: Compare the network's output with the expected output (target) using a loss function.
3. Backward Pass (Backpropagation): Compute the gradients of the loss with respect to the weights and biases of each perceptron.
4. Update Weights and Biases: Use the gradients to adjust the weights and biases using gradient descent.


dependencys: 
    - [opencv](https://github.com/opencv/opencv)