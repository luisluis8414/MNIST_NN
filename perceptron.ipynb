{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron\n",
        "\n",
        "Dieses Projekt ist eine Implementierung eines Perceptrons. Ein Perceptron ist ein einfacher, linearer Klassifikator, der Datenpunkte in zwei Klassen einteilen kann. Er basiert auf der Idee, dass die Daten durch eine lineare Entscheidungsgrenze (z. B. eine gerade Linie in 2D) getrennt werden können.\n",
        "\n",
        "## Berechnung der Ausgabewerte\n",
        "\n",
        "Mit einem Bias $b$, den Eingaben $x_i$ und den Gewichten $w_{ij}$ berechnen sich die Ausgabewerte $o_j$ zu:\n",
        "\n",
        "$$\n",
        "o_j =\n",
        "\\begin{cases}\n",
        "1 & \\text{wenn } \\sum_i w_{ij} x_i + b > 0 \\\\\n",
        "0 & \\text{ansonsten}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "## Lernregeln\n",
        "\n",
        "Für das Training des Perceptrons, ergeben sich folgende Lernregeln:\n",
        "\n",
        "1. Ist der Output gleich dem gewollten Ergebniss, wird die Gewichtung nicht verändert\n",
        "2. Ist die Ausgabe 0 aber soll den Wert 1 annehmen, werden die Gewichte inkrementiert\n",
        "3. Ist die Ausgabe 1, soll aber den Wert 0 annehmen, dann werden die Gewichte dekrementiert\n",
        "\n",
        "Mathematisch wird der Sachverhalt folgendermaßen ausgedrückt:\n",
        "\n",
        "$$\n",
        "w_{ij}^{\\text{neu}} = w_{ij}^{\\text{alt}} + \\Delta w_{ij},\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Delta w_{ij} = \\alpha \\cdot (t_j - o_j) \\cdot x_i.\n",
        "$$\n",
        "\n",
        "Dabei ist:\n",
        "\n",
        "- $\\Delta w_{ij}$ die Änderung des Gewichts $w_{ij}$ für die Verbindung zwischen der Eingabezelle $i$ und Ausgabezelle $j$,\n",
        "- $t_j$ die gewünschte Ausgabe des Neurons $j$,\n",
        "- $o_j$ die tatsächliche Ausgabe,\n",
        "- $x_i$ die Eingabe des Neurons $i$ und\n",
        "- $\\alpha > 0$ die Lernrate.\n",
        "\n",
        "### Gewichtsanpassung im Schritt $k$\n",
        "\n",
        "Eine Gewichtsaktualisierung im Schritt $k$ verläuft danach wie folgt:\n",
        "\n",
        "1. $w_{ij}(k + 1) = w_{ij}(k)$ bei korrekter Ausgabe,\n",
        "2. $w_{ij}(k + 1) = w_{ij}(k) + \\alpha x_i$ bei Ausgabe 0 und gewünschter Ausgabe 1 und\n",
        "3. $w_{ij}(k + 1) = w_{ij}(k) - \\alpha x_i$ bei Ausgabe 1 und gewünschter Ausgabe 0.\n",
        "\n",
        "\n",
        "Eine Implementierung in Python könnte so aussehen:"
      ],
      "metadata": {
        "id": "IUTv1P3upKqX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1iuIk5upIZ9",
        "outputId": "4632297c-c52e-4f2c-c8e9-a6c1db8a16d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "    Inputs: [0, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [0, 1], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 1], Target: 1, Prediction: 0, Error: 1\n",
            "    Error > 0: Incrementing weights and bias.\n",
            "    Updated Weights: [0.1 0.1], Updated Bias: 0.1\n",
            "  Weights after epoch 1: [0.1 0.1]\n",
            "  Bias after epoch 1: 0.1\n",
            "------------------------------\n",
            "Epoch 2:\n",
            "    Inputs: [0, 0], Target: 0, Prediction: 1, Error: -1\n",
            "    Error < 0: Decrementing weights and bias.\n",
            "    Updated Weights: [0.1 0.1], Updated Bias: 0.0\n",
            "    Inputs: [0, 1], Target: 0, Prediction: 1, Error: -1\n",
            "    Error < 0: Decrementing weights and bias.\n",
            "    Updated Weights: [0.1 0. ], Updated Bias: -0.1\n",
            "    Inputs: [1, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 1], Target: 1, Prediction: 0, Error: 1\n",
            "    Error > 0: Incrementing weights and bias.\n",
            "    Updated Weights: [0.2 0.1], Updated Bias: 0.0\n",
            "  Weights after epoch 2: [0.2 0.1]\n",
            "  Bias after epoch 2: 0.0\n",
            "------------------------------\n",
            "Epoch 3:\n",
            "    Inputs: [0, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [0, 1], Target: 0, Prediction: 1, Error: -1\n",
            "    Error < 0: Decrementing weights and bias.\n",
            "    Updated Weights: [0.2 0. ], Updated Bias: -0.1\n",
            "    Inputs: [1, 0], Target: 0, Prediction: 1, Error: -1\n",
            "    Error < 0: Decrementing weights and bias.\n",
            "    Updated Weights: [0.1 0. ], Updated Bias: -0.2\n",
            "    Inputs: [1, 1], Target: 1, Prediction: 0, Error: 1\n",
            "    Error > 0: Incrementing weights and bias.\n",
            "    Updated Weights: [0.2 0.1], Updated Bias: -0.1\n",
            "  Weights after epoch 3: [0.2 0.1]\n",
            "  Bias after epoch 3: -0.1\n",
            "------------------------------\n",
            "Epoch 4:\n",
            "    Inputs: [0, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [0, 1], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 0], Target: 0, Prediction: 1, Error: -1\n",
            "    Error < 0: Decrementing weights and bias.\n",
            "    Updated Weights: [0.1 0.1], Updated Bias: -0.2\n",
            "    Inputs: [1, 1], Target: 1, Prediction: 0, Error: 1\n",
            "    Error > 0: Incrementing weights and bias.\n",
            "    Updated Weights: [0.2 0.2], Updated Bias: -0.1\n",
            "  Weights after epoch 4: [0.2 0.2]\n",
            "  Bias after epoch 4: -0.1\n",
            "------------------------------\n",
            "Epoch 5:\n",
            "    Inputs: [0, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [0, 1], Target: 0, Prediction: 1, Error: -1\n",
            "    Error < 0: Decrementing weights and bias.\n",
            "    Updated Weights: [0.2 0.1], Updated Bias: -0.2\n",
            "    Inputs: [1, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 1], Target: 1, Prediction: 1, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "  Weights after epoch 5: [0.2 0.1]\n",
            "  Bias after epoch 5: -0.2\n",
            "------------------------------\n",
            "Epoch 6:\n",
            "    Inputs: [0, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [0, 1], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 1], Target: 1, Prediction: 1, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "  Weights after epoch 6: [0.2 0.1]\n",
            "  Bias after epoch 6: -0.2\n",
            "------------------------------\n",
            "Epoch 7:\n",
            "    Inputs: [0, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [0, 1], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 1], Target: 1, Prediction: 1, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "  Weights after epoch 7: [0.2 0.1]\n",
            "  Bias after epoch 7: -0.2\n",
            "------------------------------\n",
            "Epoch 8:\n",
            "    Inputs: [0, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [0, 1], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 0], Target: 0, Prediction: 0, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "    Inputs: [1, 1], Target: 1, Prediction: 1, Error: 0\n",
            "    No error: Weights and bias remain unchanged.\n",
            "  Weights after epoch 8: [0.2 0.1]\n",
            "  Bias after epoch 8: -0.2\n",
            "------------------------------\n",
            "Testing the Perceptron:\n",
            "0 AND 0 = 0\n",
            "0 AND 1 = 0\n",
            "1 AND 0 = 0\n",
            "1 AND 1 = 1\n",
            "Final Weights: [0.2 0.1]\n",
            "Final Bias: -0.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, n_inputs, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        Konstruktor: Initialisiert die Gewichte, den Bias und die Lernrate.\n",
        "        :param n_inputs: Anzahl der Eingabe-Features\n",
        "        :param learning_rate: Lernrate (default: 0.1)\n",
        "        \"\"\"\n",
        "        self.weights = np.zeros(n_inputs)  # Gewichte werden mit 0 initialisiert\n",
        "        self.bias = 0.0  # Bias wird mit 0 initialisiert\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def activate(self, x):\n",
        "        \"\"\"\n",
        "        Heaviside-Aktivierungsfunktion.\n",
        "        :param x: Eingabewert\n",
        "        :return: 1, wenn x > 0, sonst 0\n",
        "        \"\"\"\n",
        "        return 1 if x > 0 else 0\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"\n",
        "        Berechnet die Vorhersage basierend auf den Eingaben.\n",
        "        :param inputs: Eingabe-Features (Liste oder NumPy-Array)\n",
        "        :return: 1 oder 0 (Vorhersage)\n",
        "        \"\"\"\n",
        "        if len(inputs) != len(self.weights):\n",
        "            raise ValueError(\"Eingabedimension stimmt nicht mit der Anzahl der Gewichte überein!\")\n",
        "\n",
        "        # Berechnung der gewichteten Summe\n",
        "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
        "        return self.activate(weighted_sum)\n",
        "\n",
        "    def train(self, inputs, target):\n",
        "        \"\"\"\n",
        "        Trainiert den Perceptron mit einem einzelnen Trainingsbeispiel.\n",
        "        :param inputs: Eingabe-Features (Liste oder NumPy-Array)\n",
        "        :param target: Zielwert (1 oder 0)\n",
        "        \"\"\"\n",
        "        prediction = self.predict(inputs)\n",
        "        error = target - prediction\n",
        "\n",
        "        # Logging: Zeige den Fehler und die Aktion\n",
        "        print(f\"    Inputs: {inputs}, Target: {target}, Prediction: {prediction}, Error: {error}\")\n",
        "\n",
        "        # Wenn ein Fehler vorliegt, aktualisiere die Gewichte und den Bias\n",
        "        if error != 0:\n",
        "            # Logge, ob die Gewichte erhöht oder verringert werden\n",
        "            if error > 0:\n",
        "                print(\"    Error > 0: Incrementing weights and bias.\")\n",
        "            else:\n",
        "                print(\"    Error < 0: Decrementing weights and bias.\")\n",
        "\n",
        "            # Aktualisiere die Gewichte und den Bias\n",
        "            self.weights += self.learning_rate * error * np.array(inputs)\n",
        "            self.bias += self.learning_rate * error\n",
        "\n",
        "            # Logge die neuen Werte der Gewichte und des Bias\n",
        "            print(f\"    Updated Weights: {self.weights}, Updated Bias: {self.bias}\")\n",
        "        else:\n",
        "            print(\"    No error: Weights and bias remain unchanged.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialisiere den Perceptron mit 2 Inputs\n",
        "    p = Perceptron(2)\n",
        "\n",
        "    # Trainingsdaten\n",
        "    training_inputs = [\n",
        "        [0, 0],\n",
        "        [0, 1],\n",
        "        [1, 0],\n",
        "        [1, 1]\n",
        "    ]\n",
        "    training_outputs = [0, 0, 0, 1]  # Zielwerte (AND)\n",
        "\n",
        "    # Training des Perzeptrons\n",
        "    for epoch in range(8):  # 8 Epochen\n",
        "        print(f\"Epoch {epoch + 1}:\")\n",
        "        for inputs, target in zip(training_inputs, training_outputs):\n",
        "            p.train(inputs, target)\n",
        "\n",
        "        # Ausgabe der Gewichte und des Bias nach jeder Epoche\n",
        "        print(f\"  Weights after epoch {epoch + 1}: {p.weights}\")\n",
        "        print(f\"  Bias after epoch {epoch + 1}: {p.bias}\")\n",
        "        print(\"-\" * 30)  # Trennlinie für bessere Lesbarkeit\n",
        "\n",
        "    # Teste den Perceptron\n",
        "    print(\"Testing the Perceptron:\")\n",
        "    for inputs in training_inputs:\n",
        "        print(f\"{inputs[0]} AND {inputs[1]} = {p.predict(inputs)}\")\n",
        "\n",
        "    # Ausgabe der Gewichte und des Bias\n",
        "    print(\"Final Weights:\", p.weights)\n",
        "    print(\"Final Bias:\", p.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AND-Gatter Darstellung\n",
        "\n",
        "Wir trainieren unser Perceptron auf das AND-Gatter und bekommen folgende Gewichtungen und Bias:\n",
        "\n",
        "$w_1 = 0.2, w_2 = 0.1$\n",
        "\n",
        "$b$ = -0.2\n",
        "\n",
        "Wie bereits gezeigt kann die Entscheidungsgrenze für das AND-Gatter kann durch die folgende Gleichung dargestellt werden:\n",
        "\n",
        "$$ \\sum_i w_{ij} x_i + b $$\n",
        "\n",
        "also in unserem Fall:\n",
        "\n",
        "$$\n",
        "0.2x_1 + 0.1x_2 - 0.2\n",
        "$$\n",
        "\n",
        "unter Auflösung nach $x_1$ bekommen wir folgende Lösung:\n",
        "\n",
        "$$x_1 = -0.5x_2 + 1$$\n",
        "\n",
        "unter Auflösung von $x_2$:\n",
        "\n",
        "$$x_2 = -2x_1 + 2$$\n",
        "\n",
        "Führe die nächste Zelle aus um die Graphen zu visualisieren.\n"
      ],
      "metadata": {
        "id": "OILfPnCSrFHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "iframe_code = \"\"\"\n",
        "<div style=\"display: flex; justify-content: center;\">\n",
        "    <iframe src=\"https://www.desmos.com/calculator/vjfoyxwyr5?lang=de\"\n",
        "            width=\"1000\" height=\"500\" style=\"border:0;\"></iframe>\n",
        "</div>\n",
        "\"\"\"\n",
        "display(HTML(iframe_code))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "z48RmY6WzEgA",
        "outputId": "2f2ec9c9-b665-452c-f58f-8d8074fc62e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<div style=\"display: flex; justify-content: center;\">\n",
              "    <iframe src=\"https://www.desmos.com/calculator/vjfoyxwyr5?lang=de\" \n",
              "            width=\"1000\" height=\"500\" style=\"border:0;\"></iframe>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wir sehen, das unsere Punkte die einen 0 Output liefern sollen [(0, 0), (0, 1), (1,0)], jeweils unter oder auf unseren Graphen liegen. Lediglich unser 1 Output [(1, 1)] liegt über dem Graphen."
      ],
      "metadata": {
        "id": "s-Gj0LJTzuyf"
      }
    }
  ]
}